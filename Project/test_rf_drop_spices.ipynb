{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prince import MCA\n",
    "from imblearn.over_sampling import SMOTEN\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import graphviz \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_df = pd.read_csv('../dataset/recipes.csv')\n",
    "recipe_with_ingred = pd.read_csv('../dataset/recipe_with_ingredient.csv')\n",
    "food_df = pd.read_csv('../dataset/food.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find spices\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mg_apply_func(row):\n",
    "    fat, carb, protein = row['fat'] * 9, row['carbohydrate'] * 4, row['protein'] * 4\n",
    "    total = row['calories']\n",
    "    if total <= 0:\n",
    "        return 0\n",
    "    f_percent, c_percent, p_percent = fat / total, carb / total, protein / total\n",
    "    if p_percent >= 0.35:\n",
    "        if  0.15 <= f_percent <= 0.3:\n",
    "            return 1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "recipe_df['fl_mg'] = recipe_df.apply(mg_apply_func, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge with feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_recipe_df = pd.merge(recipe_with_ingred, recipe_df[['recipe_id', 'fl_mg']], on='recipe_id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature selection 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingred_spices_df = pd.read_csv('collect_spices_ingred_df.csv')\n",
    "ingred_spices_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3365, 3302)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_recipe_df = res_recipe_df.drop(labels = [str(x) for x in ingred_spices_df.food_id.values], axis = 1)\n",
    "res_recipe_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3365, 1339)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_recipe_df = res_recipe_df.loc[:, res_recipe_df.sum(axis=0)/res_recipe_df.shape[0] >= 0.0005]\n",
    "res_recipe_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UnderSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_fl_mg = res_recipe_df[res_recipe_df['fl_mg'] == 1]\n",
    "negative_fl_mg = res_recipe_df[res_recipe_df['fl_mg'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undersampling\n",
    "negative_fl_mg_rs = negative_fl_mg.sample(n= round(len(positive_fl_mg)), random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([positive_fl_mg, negative_fl_mg_rs], axis= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = final_df.iloc[:, 0:final_df.shape[1] - 1], final_df.iloc[:, final_df.shape[1] - 1]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mca = MCA(n_components = 4, n_iter=10, random_state=25)\n",
    "# mca.fit(X_train)\n",
    "# X_train = mca.transform(X_train)\n",
    "# X_test = mca.transform(X_test)\n",
    "\n",
    "# print(f\"Original class counts in training set: {Counter(y_train)}\")\n",
    "# print(f\"Original class counts in test set: {Counter(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = SMOTEN(random_state=2)\n",
    "X_train, y_train = sampler.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Original class counts: {Counter(y_train)}\")\n",
    "\n",
    "# mca.eigenvalues_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection Using Tunned Rondom Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printAccruacy(model_name, actual_test, predictions_test, actual_train=None, predictions_train=None):\n",
    "    print(f'The accuracy of {model_name} is: {accuracy_score(actual_test, predictions_test)}')\n",
    "    if actual_train is not None and predictions_train is not None:\n",
    "        print(f'The accuracy of {model_name} on training set is: {accuracy_score(actual_train, predictions_train)}')\n",
    "    \n",
    "def printReport(model_name, actual_test, predictions_test):\n",
    "    print(f'For {model_name}:')\n",
    "    print('-----------------------------------------------------')\n",
    "    print(classification_report(actual_test, predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of features: 1339\n"
     ]
    }
   ],
   "source": [
    "# print number of features in original dataset\n",
    "print('# of features:',final_df.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = final_df.iloc[:, 0:final_df.shape[1] - 1], final_df.iloc[:, final_df.shape[1] - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [200, 400, 600, 800, 1000],\n",
       " 'max_depth': [5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, None],\n",
       " 'max_features': ['sqrt', 'log2'],\n",
       " 'criterion': ['gini', 'entropy'],\n",
       " 'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       " 'min_impurity_decrease': [0.0, 0.05, 0.1],\n",
       " 'bootstrap': [True, False]}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of trees in Random Forest\n",
    "rf_n_estimators = [int(x) for x in np.linspace(200, 1000, 5)]\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "rf_max_depth = [int(x) for x in np.linspace(5, 55, 11)]\n",
    "# Add the default as a possible value\n",
    "rf_max_depth.append(None)\n",
    "\n",
    "# Number of features to consider at every split\n",
    "rf_max_features = ['sqrt', 'log2']\n",
    "\n",
    "# Criterion to split on\n",
    "rf_criterion = ['gini', 'entropy']\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "rf_min_samples_split = [int(x) for x in np.linspace(2, 10, 9)]\n",
    "\n",
    "# Minimum decrease in impurity required for split to happen\n",
    "rf_min_impurity_decrease = [0.0, 0.05, 0.1]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "rf_bootstrap = [True, False]\n",
    "\n",
    "# Create the grid\n",
    "rf_grid = {'n_estimators': rf_n_estimators,\n",
    "               'max_depth': rf_max_depth,\n",
    "               'max_features': rf_max_features,\n",
    "               'criterion': rf_criterion,\n",
    "               'min_samples_split': rf_min_samples_split,\n",
    "               'min_impurity_decrease': rf_min_impurity_decrease,\n",
    "               'bootstrap': rf_bootstrap}\n",
    "rf_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model to be tuned\n",
    "rf_base = RandomForestClassifier()\n",
    "\n",
    "# Create the random search Random Forest\n",
    "rf_random = RandomizedSearchCV(estimator = rf_base, param_distributions = rf_grid, scoring='f1',\n",
    "                               n_iter = 200, cv = 5, verbose = 2, random_state = 0, \n",
    "                               n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "# View the best parameters from the random search\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_feature_select = RandomForestClassifier() \n",
    "# n_estimators=400, \n",
    "# min_samples_split=10,\n",
    "# min_impurity_decrease=0.05,\n",
    "# max_features='sqrt',\n",
    "# max_depth=20,\n",
    "# criterion='entropy',\n",
    "# bootstrap=True\n",
    "rf_feature_select = rf_feature_select.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SelectFromModel(rf_feature_select, prefit=True)\n",
    "new_features_index = model.get_support()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of features: 309\n"
     ]
    }
   ],
   "source": [
    "# print number of features after seleciton\n",
    "num_new_features = sum([1 for i in new_features_index if i])\n",
    "print('# of features:',num_new_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>food_id</th>\n",
       "      <th>food_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39536</td>\n",
       "      <td>Honey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3092</td>\n",
       "      <td>Egg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>36492</td>\n",
       "      <td>Russet Potatoes (Flesh and Skin)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4881229</td>\n",
       "      <td>Skinless Chicken Breast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36320</td>\n",
       "      <td>Carrots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3786</th>\n",
       "      <td>36237</td>\n",
       "      <td>Alfalfa Seeds (Sprouted)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3790</th>\n",
       "      <td>36668</td>\n",
       "      <td>Waterchestnuts (Solids and Liquids, Canned)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>35751</td>\n",
       "      <td>Apricot Nectar (Without Added Ascorbic Acid, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>37492</td>\n",
       "      <td>Beef Knuckle (Tip Side, Steak, Lean Only, Trim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3799</th>\n",
       "      <td>37739</td>\n",
       "      <td>Table Wine</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>618 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      food_id                                          food_name\n",
       "1       39536                                              Honey\n",
       "2        3092                                                Egg\n",
       "6       36492                   Russet Potatoes (Flesh and Skin)\n",
       "11    4881229                            Skinless Chicken Breast\n",
       "12      36320                                            Carrots\n",
       "...       ...                                                ...\n",
       "3786    36237                           Alfalfa Seeds (Sprouted)\n",
       "3790    36668        Waterchestnuts (Solids and Liquids, Canned)\n",
       "3794    35751  Apricot Nectar (Without Added Ascorbic Acid, C...\n",
       "3795    37492  Beef Knuckle (Tip Side, Steak, Lean Only, Trim...\n",
       "3799    37739                                         Table Wine\n",
       "\n",
       "[618 rows x 2 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food_df[food_df['food_id'].isin(X.loc[:, new_features_index].columns[1:])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of random forest is: 0.7075471698113207\n",
      "The accuracy of random forest on training set is: 1.0\n"
     ]
    }
   ],
   "source": [
    "printAccruacy('random forest', y_test, rf_feature_select.predict(X_test), y_train, rf_feature_select.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of random forest is: 0.7264150943396226\n",
      "The accuracy of random forest on training set is: 1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(420, 309)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_X = X.loc[:, new_features_index]\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_X , y, test_size=0.20)\n",
    "rf_feature_select = RandomForestClassifier() \n",
    "rf_feature_select = rf_feature_select.fit(X_train, y_train)\n",
    "printAccruacy('random forest', y_test, rf_feature_select.predict(X_test), y_train, rf_feature_select.predict(X_train))\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "new_X = X.loc[:, new_features_index]\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_X , y, test_size=0.20)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_importance = RFECV(SVC(kernel=\"linear\"), scoring='accuracy')\n",
    "# feature_importance.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training - Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "path = clf.cost_complexity_pruning_path(X_train, y_train)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n",
    "clfs = []\n",
    "\n",
    "for ccp_alpha in ccp_alphas:\n",
    "    clf = DecisionTreeClassifier(random_state=0, ccp_alpha=ccp_alpha)\n",
    "    clf.fit(X_train, y_train)\n",
    "    clfs.append(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "tree_depths = [clf.tree_.max_depth for clf in clfs]\n",
    "plt.figure(figsize=(10,  6))\n",
    "plt.plot(ccp_alphas, tree_depths)\n",
    "plt.xlabel(\"effective alpha\")\n",
    "plt.ylabel(\"total depth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "acc_scores = [accuracy_score(y_val, clf.predict(X_val)) for clf in clfs]\n",
    "\n",
    "tree_depths = [clf.tree_.max_depth for clf in clfs]\n",
    "plt.figure(figsize=(10,  6))\n",
    "plt.grid()\n",
    "plt.plot(ccp_alphas, acc_scores)\n",
    "plt.xlabel(\"effective alpha\")\n",
    "plt.ylabel(\"Accuracy scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def getMaxInd(lst):\n",
    "    ind = 0\n",
    "    val = -1\n",
    "    for i in range(len(lst)):\n",
    "        if lst[i] >= val:\n",
    "            ind = i\n",
    "            val = lst[i]\n",
    "    return ind\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ccp_alphas[getMaxInd(acc_scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum number of levels in tree\n",
    "dt_max_depth = [int(x) for x in range(5,50)]\n",
    "# Add the default as a possible value\n",
    "dt_max_depth.append(None)\n",
    "\n",
    "# Number of features to consider at every split\n",
    "dt_max_features = ['sqrt', 'log2']\n",
    "\n",
    "# Criterion to split on\n",
    "dt_criterion = ['gini', 'entropy']\n",
    "\n",
    "# Minimum number of samples required to split a node\n",
    "dt_min_samples_split = [int(x) for x in np.linspace(2, 10, 9)]\n",
    "\n",
    "# Minimum decrease in impurity required for split to happen\n",
    "dt_min_impurity_decrease = [0.0, 0.05, 0.1]\n",
    "\n",
    "# Create the grid\n",
    "dt_grid = {'max_depth': dt_max_depth,\n",
    "               'max_features': dt_max_features,\n",
    "               'criterion': dt_criterion,\n",
    "               'min_samples_split': dt_min_samples_split,\n",
    "               'min_impurity_decrease': dt_min_impurity_decrease}\n",
    "# dt_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model to be tuned\n",
    "dt_base = DecisionTreeClassifier()\n",
    "\n",
    "# Create the random search Random Forest\n",
    "dt_random = GridSearchCV(estimator = dt_base, param_grid = dt_grid, scoring='f1',\n",
    "                              cv = 5, verbose = 2, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "dt_random.fit(X_train, y_train)\n",
    "\n",
    "# View the best parameters from the random search\n",
    "dt_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier(min_samples_split=10,\n",
    "                                  min_impurity_decrease=0,\n",
    "                                  max_features='log2',\n",
    "                                  max_depth=42,\n",
    "                                  criterion='entropy'\n",
    "                                 )\n",
    "dt_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The accuracy of DT is: {accuracy_score(y_test, dt_model.predict(X_test))}')\n",
    "print(f'The accuracy of DT on training set is: {accuracy_score(y_train, dt_model.predict(X_train))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printReport('decision tree', y_test, dt_model.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[y_test == 1].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = DecisionTreeClassifier(ccp_alpha=ccp_alphas[getMaxInd(acc_scores)])\n",
    "tree_model.fit(X_train, y_train)\n",
    "TreePredict = tree_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The accuracy of DT is: {accuracy_score(y_test, TreePredict)}')\n",
    "print(f'The accuracy of DT on training set is: {accuracy_score(y_train, tree_model.predict(X_train))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM and Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cs = np.linspace(0.01, 10, 50)\n",
    "\n",
    "gammas = np.linspace(0.01, 1, 50)\n",
    "# np.linspace(0.01, 0.02, 30)\n",
    "\n",
    "svc_grid = {'C': Cs, 'gamma' : gammas}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_grid_search = GridSearchCV(SVC(kernel='rbf'), svc_grid, cv=5, n_jobs = -1, verbose = 2, scoring='f1')\n",
    "svc_grid_search.fit(X_train, y_train)\n",
    "svc_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model = SVC(C=5.1, gamma=0.01)\n",
    "svc_model.fit(X_train, y_train)\n",
    "SvcPredict = svc_model.predict(X_test)\n",
    "printAccruacy('SVC model', y_test, SvcPredict, y_train, svc_model.predict(X_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression()\n",
    "logistic.fit(X_train,y_train) \n",
    "\n",
    "tree_model = DecisionTreeClassifier(criterion='entropy')\n",
    "tree_model.fit(X_train, y_train )\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train )\n",
    "\n",
    "svc_model = SVC()\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(max_iter=300)\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticPredict = logistic.predict(X_test)\n",
    "TreePredict = tree_model.predict(X_test)\n",
    "SvcPredict = svc_model.predict(X_test)\n",
    "mlpPredict = mlp.predict(X_test)\n",
    "rfPredict = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The accuracy of logistic regression is: {accuracy_score(y_test, LogisticPredict)}')\n",
    "print(f'The accuracy of DT is: {accuracy_score(y_test, TreePredict)}')\n",
    "print(f'The accuracy of SVC is: {accuracy_score(y_test, SvcPredict)}')\n",
    "print(f'The accuracy of MLP is: {accuracy_score(y_test, mlpPredict)}')\n",
    "print(f'The accuracy of RF is: {accuracy_score(y_test, rfPredict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printReport('decision tree', y_test, TreePredict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'weights: {logistic.coef_}, bias_term: {logistic.intercept_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_f_importance = tree_model.feature_importances_\n",
    "rf_f_importance = rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapWithIndex(lst):\n",
    "    res = []\n",
    "    for i in range(len(lst)):\n",
    "        res.append((i, lst[i]))\n",
    "    return res\n",
    "\n",
    "def filterNonImportant(lst, threshold):\n",
    "    res = []\n",
    "    for i in lst:\n",
    "        if i[1] >= threshold:\n",
    "            res.append(i)\n",
    "    return res\n",
    "\n",
    "def getIndex(lst):\n",
    "    res = []\n",
    "    for i in lst:\n",
    "        res.append(i[0])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_f_importance = mapWithIndex(tree_f_importance)\n",
    "rf_f_importance = mapWithIndex(rf_f_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_f_importance = filterNonImportant(rf_f_importance, 0.001)\n",
    "tree_f_importance = filterNonImportant(tree_f_importance, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tree_f_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_f_importance.sort(key=lambda x : x[0])\n",
    "feature_index = getIndex(tree_f_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X = X.iloc[:, feature_index]\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic = LogisticRegression()\n",
    "logistic.fit(X_train,y_train) \n",
    "\n",
    "tree_model = DecisionTreeClassifier(criterion='entropy')\n",
    "tree_model.fit(X_train, y_train )\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train )\n",
    "\n",
    "svc_model = SVC()\n",
    "svc_model.fit(X_train, y_train)\n",
    "\n",
    "mlp = MLPClassifier(random_state=1, max_iter=300, activation='logistic')\n",
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticPredict = logistic.predict(X_test)\n",
    "TreePredict = tree_model.predict(X_test)\n",
    "SvcPredict = svc_model.predict(X_test)\n",
    "mlpPredict = mlp.predict(X_test)\n",
    "rfPredict = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The accuracy of logistic regression is: {accuracy_score(y_test, LogisticPredict)}')\n",
    "print(f'The accuracy of DT is: {accuracy_score(y_test, TreePredict)}')\n",
    "print(f'The accuracy of SVC is: {accuracy_score(y_test, SvcPredict)}')\n",
    "print(f'The accuracy of MLP is: {accuracy_score(y_test, mlpPredict)}')\n",
    "print(f'The accuracy of RF is: {accuracy_score(y_test, rfPredict)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
